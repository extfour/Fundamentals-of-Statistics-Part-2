# Начнем с простого и вспомним, как применять логистическую регрессию в R.
# Напишите функцию get_coefficients, которая получает на вход dataframe с двумя
# переменными x ( фактор с произвольным числом градаций) и y ( фактор с двумя градациями ﻿).
# Функция строит логистическую модель, где y — зависимая переменная, а x — независимая,
# и возвращает вектор со значением экспоненты коэффициентов модели.
#
# Пример работы функции.
#
#
# > test_data <- read.csv("https://stepik.org/media/attachments/course/524/test_data_01.csv")
# > # переведем переменные в фактор
#   > test_data <- transform(test_data, x = ﻿factor(x), y = factor(y))
# > get_coefficients(test_data) (Intercept)         x2         x3   0.9000000 2.5396825 0.6666667 ﻿

df <- read.csv("https://stepik.org/media/attachments/course/524/test_data_01.csv")

get_coefficients <- function(df){
  return(exp(coef(glm(df[[2]] ~ df[[1]], family ='binomial' ))))
}

test_data <- transform(df, x = factor(x), y = factor(y))
get_coefficients(test_data)




# Если в нашей модели есть количественные предикторы, то в интерцепте мы будем иметь
# значение, соответствующее базовому уровню категориальных предикторов и нулевому уровню
# количественных. Это не всегда осмысленно. Например, нам не интересен прогноз для людей
# нулевого возраста или роста. В таких ситуациях количественную переменную имеет смысл
# предварительно центрировать так, чтобы ноль являлся средним значением переменной.
# Самый простой способ центрировать переменную — отнять от каждого наблюдения среднее
# значение всех наблюдений.
# xcentered(i) =x(i) − mean(x)
#
# В этом задании вашей задачей будет  написать функцию centered, которая получает на
# вход датафрейм и имена переменных, которые необходимо центрировать так, как это описано
# выше. Функция должна возвращать этот же датафрейм, только с центрированными
# указанными переменными.
#
# Пример работы функции:
#

centered <- function(df, var_names){
  df[var_names] <- sapply(df[var_names], function(x) x - mean(x))
  return(df)
}

df <- read.csv("https://stepik.org/media/attachments/course/524/cen_data.csv")
test_data[ c("X4", "X2", "X1")]

var_names = c("X4", "X2", "X1")
centered(df, var_names)






# Представьте, что мы работаем в аэропорту в службе безопасности и сканируем багаж пассажиров.
# В нашем распоряжении есть информация о результатах проверки багажа за предыдущие месяцы.
# Про каждую вещь мы знаем:
#
#   являлся ли багаж запрещенным - is_prohibited (No - разрешенный, Yes - запрещенный)
# его массу (кг) - weight
# длину (см) - length
# ширину (см) - width
# тип багажа (сумка или чемодан) - type.
#
# Напишите функцию get_features , которая получает на вход набор данных о багаже.
# Строит логистическую регрессию, где зависимая переменная ﻿ - ﻿являлся ли багаж запрещенным,
# а предикторы - остальные переменные,﻿ и возвращает вектор с названиями статистически
# значимых переменных (p < 0.05) (в модели без взаимодействия). Если в данных нет значимых
# предикторов, функция возвращает строку с сообщением  "Prediction makes no sense".
#
# Пример работы функции и описание переменных:
#
# test_data <- read.csv("https://stepik.org/media/attachments/course/524/test_luggage_1.csv")
# str(test_data)
#
# 'data.frame':	60 obs. of  5 variables:
# $ is_prohibited: Factor w/ 2 levels "No","Yes": 1 1 1 1 1 1 1 1 1 1 ...
# $ weight       : int  69 79 82 81 84 81 64 76 77 88 ...
# $ length       : int  53 52 54 50 48 51 53 52 53 52 ...
# $ width        : int  17 21 20 23 19 20 16 20 23 23 ...
# $ type         : Factor w/ 2 levels "Bag","Suitcase": 2 1 2 1 2 1 2 1 2 1 ...
# > get_features(test_data)
# [1] "Prediction makes no sense"
#
df <- read.csv("https://stepik.org/media/attachments/course/524/test_luggage_2.csv")
# > str(test_data)
# > get_features(test_data)
# [1] "length" "width"  "type"
# # обратите внимаение функция возвращает именно названия исходных переменных, а не typeBad или typeSuitcase! Ведь нас интересует именно влияние переменной в ﻿целом.
#
# Подсказка. Для отбора значимых предикторов воспользуйтесь функцией anova()
#
# fit <- glm(x ~ y, data, family = "binomial")
# result <- anova(fit, test = "Chisq") #тут и будет вся нужная информация!

install.packages("tidyverse")
library(tidyverse)

get_features <- function(df){

  df <- mutate(df,
               is_prohibited = factor(is_prohibited, labels = c('No', 'Yes')),
               type = factor(type, labels = c('Bag', 'Suitcase'))
               )
  fit <- glm(is_prohibited ~ weight + length + width + type, data = df, family = 'binomial')
  result <- anova(fit, test = "Chisq")
  valid <- result$Pr < 0.05
  if (sum(valid, na.rm=T) == 0) {
    return("Prediction makes no sense")
  } else {
    return(rownames(subset(result,`Pr(>Chi)`<0.05)))
  }
}







#
# Интересной особенностью логистической регрессии является тот факт, что ее предсказания
# — это не конкретный класс, к которому мы отнесем новое наблюдение, а вероятность отнесения
# к каждому из классов! Если вас интересует, как принимать решение о классификации новых
# объектов в логистической регрессии, посмотрите наш урок по этой теме в курсе по R,
# где мы разбираем этот вопрос.
#
# В результате, построив регрессионную модель, мы можем сделать вероятностное предсказание
# для каждого нового наблюдения. Иногда при решении практических задач бывает важным
# обратить внимание на те объекты, которые получили максимальное значение вероятности
# принадлежности к одному из классов.
#
# Продолжим нашу работу в службе безопасности! Разобравшись с тем, какие предикторы
# могут помогать нам предсказывать запрещенный багаж, давайте применим наши знания
# для повышения безопасности в аэропорту. Обучим наш алгоритм различать запрещенный и
# разрешенный багаж на уже имеющихся данных и применим его для сканирования нового багажа!
#
# Напишите функцию, которая принимает на вход два набора данных. Первый dataframe, как
# и в предыдущей задаче, содержит информацию об уже осмотренном багаже (запрещенный или нет,
# вес, длина, ширина, тип сумки).
#
# Второй набор данных — это информация о новом багаже, который сканируется прямо сейчас.
# В данных также есть информация:  вес, длина, ширина, тип сумки и имя пассажира
# (смотри описание переменных в примере).
#
# Используя первый набор данных, обучите регрессионную модель различать запрещенный и
# разрешенный багаж. При помощи полученной модели для каждого наблюдения в новых данных
# предскажите вероятность того, что багаж является запрещенным. Пассажиров, чей багаж
# получил максимальное значение вероятности, мы попросим пройти дополнительную проверку.
#
# Итого, ваша функция принимает два набора данных и возвращает имя пассажира с наиболее
# подозрительным багажом. Если несколько пассажиров получили максимальное значение вероятности,
# то верните вектор с несколькими именами.
#
# В этой задаче для предсказания будем использовать все предикторы, даже если некоторые из
# них оказались незначимыми. Для предсказания стройте модель без взаимодействия предикторов.
#
# Пример работы функции:


df <- read.csv("https://stepik.org/media/attachments/course/524/test_data_passangers.csv")
# > str(test_data)
# 'data.frame':  30 obs. of  5 variables:
#   $ is_prohibited: Factor w/ 2 levels "No","Yes": 1 1 1 1 1 1 1 1 1 1 ...
# $ weight       : int  81 72 79 89 87 91 74 76 74 84 ...
# $ length       : int  49 49 60 49 54 42 54 49 49 53 ...
# $ width        : int  13 25 22 24 13 25 17 22 12 26 ...
# $ type         : Factor w/ 2 levels "Bag","Suitcase": 2 2 2 2 2 2 2 2 2 2 ...
#
data_for_predict <-read.csv("https://stepik.org/media/attachments/course/524/predict_passangers.csv")
# > str(data_for_predict)
# 'data.frame':  10 obs. of  5 variables:
#   $ weight    : int  81 80 76 87 80 70 95 72 73 76
# $ length    : int  56 47 54 59 59 53 54 42 45 49
# $ width     : int  24 18 20 19 19 21 19 22 23 18
# $ type      : Factor w/ 2 levels "Bag","Suitcase": 2 1 1 1 2 1 2 2 2 1
# $ passangers: Factor w/ 10 levels "Anatoliy","Bob",..: 2 1 3 6 9 8 10 5 4 7
#
# > most_suspicious(test_data, data_for_predict)
# [1] Svetozar # пассажира звали Светозар!

df$is_prohibited <- as.factor(df$is_prohibited)
df$type <- as.factor(df$type)
data_for_predict$type <- as.factor(data_for_predict$type)



most_suspicious <- function(df, data_for_predict){
  fit <- glm(is_prohibited ~ weight + length + width + type, data = df, family = 'binomial')

  y_full <- predict(fit, newdata = data_for_predict, type = "response")
  idx <- which(y_full == max(y_full), arr.ind = TRUE)
  return(data_for_predict$passangers[idx])
}





# Напишите функцию normality_test, которая получает на вход dataframe с
# произвольным количеством переменных разных типов (количественные, строки, факторы)
# и проверяет нормальность распределения количественных переменных. Функция должна
# возвращать вектор значений p-уровней значимости теста shapiro.test для каждой
# количественной переменной.
#
# Вот такая задача уж точно встретится вам в реальной практике не один раз!
#
#   > normality_test(iris)
# Sepal.Length  Sepal.Width Petal.Length  Petal.Width
# 1.018116e-02 1.011543e-01 7.412263e-10 1.680465e-08
#
# > test <- read.csv("https://stepik.org/media/attachments/course/524/test.csv")
# > normality_test(test)
# V1          V3          V5          V6
# 0.568208352 0.245833708 0.314189423 0.009373741

df <- read.csv("https://stepik.org/media/attachments/course/524/test.csv")

normality_test <- function(df){
  df <- df[sapply(df,is.numeric)]
  return(unlist(sapply(df, shapiro.test)[2,]))
}

normality_test(df)






# Напишите функцию smart_anova, которая получает на вход dataframe с двумя переменными x и y.
# Переменная x — это количественная переменная, переменная y - фактор, ﻿разбивает наблюдения
# на три группы.
#
# Если распределения во всех группах значимо не отличаются от нормального, а дисперсии в
# группах гомогенны, функция должна сравнить три группы при помощи дисперсионного анализа
# и вернуть ﻿именованный вектор со значением p-value, имя элемента — "ANOVA".
#
# Если хотя ﻿бы в одной группе распределение значимо отличается от нормального или дисперсии
# негомогенны, функция сравнивает группы при помощи критерия Краскела — Уоллиса и возвращает
# именованный вектор со значением p-value, имя вектора  — "KW".
#
# Распределение будем считать значимо отклонившимся от нормального, если в тесте
# shapiro.test() p < 0.05.
#
# Дисперсии будем считать не гомогенными, если в тесте bartlett.test() p < 0.05.
#
# Пример работы функции:
#
# > test_data <- read.csv("https://stepik.org/media/attachments/course/524/s_anova_test.csv")
# > str(test_data)
# 'data.frame':	30 obs. of  2 variables:
#   $ x: num  1.08 0.07 -1.02 -0.45 0.81 -1.27 -0.75 1.47 -0.2 -1.48 ...
# $ y: Factor w/ 3 levels "A","B","C": 1 1 1 1 1 1 1 1 1 1 ...
# > smart_anova(test_data)
# ANOVA
# 0.265298
#
# Подсказка:
# Вытащить значение p-value из результатов применения функции aov() — та еще задача!
# Один из вариантов:
#
# fit <- aov(x ~ y, test)
# p_value <- summary(fit)[[1]]$'Pr(>F)'[1]